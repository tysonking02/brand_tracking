{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1043b9f",
   "metadata": {},
   "source": [
    "### Create Maps from Survey Options to CoStar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f18f018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_map = {\n",
    "    'Atlanta': 'Atlanta, GA',\n",
    "    'Austin': 'Austin, TX',\n",
    "    'Charlotte': 'Charlotte, NC',\n",
    "    'Columbus': 'Columbus, OH',\n",
    "    'DC': 'Washington, DC',\n",
    "    'Dallas': 'Dallas, TX',\n",
    "    'Denver': 'Denver, CO',\n",
    "    'Houston': 'Houston, TX',\n",
    "    'Nashville': 'Nashville, TN',\n",
    "    'Orlando': 'Orlando, FL',\n",
    "    'Phoenix': 'Phoenix, AZ',\n",
    "    'Raleigh': 'Raleigh, NC',\n",
    "    'South Florida': 'Miami, FL',\n",
    "    'Tampa': 'Tampa, FL',\n",
    "    'Tucson': 'Tucson, AZ'\n",
    "}\n",
    "\n",
    "manager_map = {\n",
    "    'amli': 'AMLI',\n",
    "    'arium': 'ARIUM',\n",
    "    'avalon': 'AvalonBay',\n",
    "    'bell': 'Bell',\n",
    "    'bozzuto': 'Bozzuto',\n",
    "    'broadstone': 'Broadstone',  \n",
    "    'camden': 'Camden',\n",
    "    'cortland': 'Cortland',\n",
    "    'cushman_&_wakefield': 'Pinnacle', \n",
    "    'encantada': 'HSL', \n",
    "    'gables': 'Gables', \n",
    "    # 'greenwater': 'Greenwater',\n",
    "    'greystar': 'Greystar',\n",
    "    'hsl': 'HSL', \n",
    "    'lincoln': 'Willow Bridge', \n",
    "    'maa': 'MAA',\n",
    "    'mark_taylor': 'Mark Taylor',\n",
    "    'northstar': 'Northstar', \n",
    "    'northwood': 'Northwood Ravin', \n",
    "    'pb_bell': 'Bell',\n",
    "    'pinnacle': 'Pinnacle',\n",
    "    'post': 'Post Road',\n",
    "    'rpm_living': 'RPM',\n",
    "    'walton': 'Walton Communities', \n",
    "    'weidner': 'Weidner',\n",
    "    'windsor': 'Windsor'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a65991",
   "metadata": {},
   "source": [
    "### Read in Raw HelloData Property Details and Reference File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5b2c021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyson.king\\AppData\\Local\\Temp\\ipykernel_36868\\2301443739.py:10: DtypeWarning: Columns (48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  property_details = pd.read_csv('data/property_details.csv')\n"
     ]
    }
   ],
   "source": [
    "hellodata_costar_ref = pd.read_csv('data/hellodata_costar_ref.csv')\n",
    "\n",
    "hellodata_cols = [\n",
    "    'UnitCount', 'NumberStories',\n",
    "    'PropertyQuality', 'BuildingAge', 'BedroomQuality', \n",
    "    'KitchenQuality', 'BathroomQuality', 'DiningRoomQuality', 'CommonAreasQuality', \n",
    "    'FitnessCenterQuality', 'LaundryRoomQuality', 'LivingRoomQuality', 'MainEntranceQuality'\n",
    "]\n",
    "\n",
    "property_details = pd.read_csv('data/property_details.csv')\n",
    "property_details = property_details[['HelloDataID'] + hellodata_cols]\n",
    "\n",
    "property_details = pd.merge(property_details, hellodata_costar_ref, left_on='HelloDataID', right_on='property_id', how='outer').drop(columns=['property_id']).dropna(subset='HelloDataID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7196666",
   "metadata": {},
   "source": [
    "### Read in Raw CoStar Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "514c1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "costar_export = pd.read_csv('data/branded_sites.csv')\n",
    "\n",
    "costar_export = costar_export[['PropertyID', 'MarketName', 'SubMarketName', 'manager', 'Latitude', 'Longitude']]\n",
    "\n",
    "costar_export = pd.merge(costar_export, property_details, left_on='PropertyID', right_on='costar_id', how='left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e9416",
   "metadata": {},
   "source": [
    "### Read in Raw Survey Data and Format Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "917b6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_survey_data = pd.read_csv('data/raw_survey_data.csv',encoding='latin1')\\\n",
    "    .rename(columns={'Market': 'market',\n",
    "                     'Which of the following best describes your current living situation?':'living',\n",
    "                     'What is your combined, annual household income?':'income',\n",
    "                     'What is theÂ\\xa0total monthly rent payment (for all bedrooms)Â\\xa0where you live? The total rent forÂ\\xa0all bedrooms, not just your portion of the rent.Â\\xa0':'total_rent',\n",
    "                     'What is your age?':'age',\n",
    "                     'Cortland Unaided': 'cortland_unaided',\n",
    "                     'Camden Unaided': 'camden_unaided',\n",
    "                     'Greystar Unaided': 'greystar_unaided',\n",
    "                     'MAA Unaided': 'maa_unaided'})\n",
    "\n",
    "raw_survey_data['cortland_unaided'] = raw_survey_data['cortland_unaided'].notna().astype(int)\n",
    "raw_survey_data['camden_unaided']   = raw_survey_data['camden_unaided'].notna().astype(int)\n",
    "raw_survey_data['greystar_unaided'] = raw_survey_data['greystar_unaided'].notna().astype(int)\n",
    "raw_survey_data['maa_unaided']      = raw_survey_data['maa_unaided'].notna().astype(int)\n",
    "\n",
    "aided_cols = [col for col in raw_survey_data.columns if col.startswith('<strong>')]\n",
    "\n",
    "for col in aided_cols:\n",
    "    match = re.search(r'<strong>(.*?)</strong>', col)\n",
    "    if match:\n",
    "        brand = match.group(1).strip().lower().replace(' ', '_')\n",
    "        new_col = f\"{brand}_aided\"\n",
    "        raw_survey_data[new_col] = raw_survey_data[col].notna().astype(int)\n",
    "\n",
    "survey_df = raw_survey_data[[\n",
    "    col for col in raw_survey_data.columns\n",
    "    if col in ['market', 'living', 'income', 'total_rent', 'age']\n",
    "    or col.endswith('_aided') or col.endswith('_unaided')\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1a2b86",
   "metadata": {},
   "source": [
    "### Aggregate Survey Data to get Income, Rent and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5e669247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyson.king\\AppData\\Local\\Temp\\ipykernel_36868\\2906079784.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  survey_df['income'] = survey_df['income'].apply(extract_upper_income)\n",
      "C:\\Users\\tyson.king\\AppData\\Local\\Temp\\ipykernel_36868\\2906079784.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  survey_df['total_rent'] = survey_df['total_rent'].apply(extract_upper_rent)\n"
     ]
    }
   ],
   "source": [
    "def extract_upper_income(val):\n",
    "    if 'or more' in val:\n",
    "        return 200000\n",
    "    match = re.search(r'under\\s*\\$?([\\d,]+)', val)\n",
    "    if match:\n",
    "        return int(match.group(1).replace(',', ''))\n",
    "    return None\n",
    "\n",
    "def extract_upper_rent(val):\n",
    "    if 'More than' in val:\n",
    "        return 3000\n",
    "    match = re.search(r'\\$[\\d,]+ - \\$([\\d,]+)', val)\n",
    "    if match:\n",
    "        return int(match.group(1).replace(',', ''))\n",
    "    return None\n",
    "\n",
    "\n",
    "survey_df['income'] = survey_df['income'].apply(extract_upper_income)\n",
    "survey_df['total_rent'] = survey_df['total_rent'].apply(extract_upper_rent)\n",
    "\n",
    "market_demos = survey_df.groupby('market').agg({\n",
    "    'income': 'mean',\n",
    "    'age': 'mean',\n",
    "    'total_rent': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "market_demos['market'] = market_demos['market'].map(market_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae0214",
   "metadata": {},
   "source": [
    "### Aggregate Survey Data to get Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f98a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aided_cols = [col for col in raw_survey_data.columns if col.endswith('_aided')]\n",
    "\n",
    "melted = survey_df[['market'] + aided_cols].melt(\n",
    "    id_vars='market',\n",
    "    value_vars=aided_cols,\n",
    "    var_name='manager',\n",
    "    value_name='recognized'\n",
    ")\n",
    "\n",
    "melted['manager'] = melted['manager'].str.replace('_aided', '', regex=False)\n",
    "\n",
    "brand_recognition = (\n",
    "    melted.groupby(['market', 'manager'], as_index=False)['recognized']\n",
    "    .mean()\n",
    "    .rename(columns={'recognized': 'recognition'})\n",
    ")\n",
    "\n",
    "brand_recognition['market'] = brand_recognition['market'].map(market_map)\n",
    "brand_recognition['manager'] = brand_recognition['manager'].map(manager_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76591374",
   "metadata": {},
   "source": [
    "### Aggregate HelloData Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9eeee9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_exclude = ['PropertyID', 'Latitude', 'Longitude', 'HelloDataID', 'costar_id', 'SubMarketName']\n",
    "cols_to_agg = [col for col in costar_export.columns if col not in cols_to_exclude + ['MarketName', 'manager']]\n",
    "\n",
    "costar_export[cols_to_agg] = costar_export[cols_to_agg].apply(\n",
    "    lambda col: col.fillna(col.mean()) if col.dtype.kind in 'biufc' else col\n",
    ")\n",
    "\n",
    "manager_metrics = (\n",
    "    costar_export.groupby(['MarketName', 'manager'])[cols_to_agg]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "for col in cols_to_agg:\n",
    "    manager_metrics[col] = manager_metrics[col].fillna(manager_metrics[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effecb15",
   "metadata": {},
   "source": [
    "### Create Location Quantification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e90d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "costar_export['lat_bin'] = costar_export['Latitude'].round(2)\n",
    "costar_export['lon_bin'] = costar_export['Longitude'].round(2)\n",
    "\n",
    "tile_density = (\n",
    "    costar_export.groupby(['MarketName', 'lat_bin', 'lon_bin'])\n",
    "    .agg(\n",
    "        total_units=('UnitCount', 'sum'),\n",
    "        total_assets=('PropertyID', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "top_tiles = (\n",
    "    tile_density.sort_values(['MarketName', 'total_units'], ascending=[True, False])\n",
    "    .groupby('MarketName')\n",
    "    .head(3)  # Adjust to 2, 5, etc. depending on your needs\n",
    "    .copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e8e04050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarketName</th>\n",
       "      <th>lat_bin</th>\n",
       "      <th>lon_bin</th>\n",
       "      <th>total_units</th>\n",
       "      <th>total_assets</th>\n",
       "      <th>center_lat</th>\n",
       "      <th>center_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>42.34</td>\n",
       "      <td>-71.08</td>\n",
       "      <td>6759.454800</td>\n",
       "      <td>27</td>\n",
       "      <td>42.34</td>\n",
       "      <td>-71.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>42.34</td>\n",
       "      <td>-71.10</td>\n",
       "      <td>6008.404267</td>\n",
       "      <td>24</td>\n",
       "      <td>42.34</td>\n",
       "      <td>-71.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>42.35</td>\n",
       "      <td>-71.14</td>\n",
       "      <td>4756.653378</td>\n",
       "      <td>19</td>\n",
       "      <td>42.35</td>\n",
       "      <td>-71.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MarketName  lat_bin  lon_bin  total_units  total_assets  center_lat  \\\n",
       "5443  Boston, MA    42.34   -71.08  6759.454800            27       42.34   \n",
       "5441  Boston, MA    42.34   -71.10  6008.404267            24       42.34   \n",
       "5461  Boston, MA    42.35   -71.14  4756.653378            19       42.35   \n",
       "\n",
       "      center_lon  \n",
       "5443      -71.08  \n",
       "5441      -71.10  \n",
       "5461      -71.14  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tiles[top_tiles['MarketName'] == 'Boston, MA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7562c7",
   "metadata": {},
   "source": [
    "### Final Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d1a6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics = pd.merge(manager_metrics, brand_recognition, left_on=['MarketName', 'manager'], right_on=['market', 'manager'], how='right')\n",
    "final_metrics = pd.merge(final_metrics, market_demos, on='market', how='left')\n",
    "\n",
    "final_metrics = final_metrics.drop(columns=['MarketName']).dropna(subset='NumberStories')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28efde",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "47756d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:            recognition   R-squared (uncentered):                   0.717\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.689\n",
      "Method:                 Least Squares   F-statistic:                              25.83\n",
      "Date:                Wed, 09 Jul 2025   Prob (F-statistic):                    1.33e-36\n",
      "Time:                        10:23:20   Log-Likelihood:                          141.85\n",
      "No. Observations:                 179   AIC:                                     -251.7\n",
      "Df Residuals:                     163   BIC:                                     -200.7\n",
      "Df Model:                          16                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "UnitCount              5.31e-05      0.000      0.413      0.680      -0.000       0.000\n",
      "NumberStories           -0.0057      0.003     -1.953      0.053      -0.012    6.33e-05\n",
      "PropertyQuality         -0.1071      0.763     -0.140      0.889      -1.613       1.399\n",
      "BuildingAge              0.0025      0.001      2.007      0.046       4e-05       0.005\n",
      "BedroomQuality           1.1078      0.395      2.807      0.006       0.329       1.887\n",
      "KitchenQuality          -0.2050      0.396     -0.517      0.606      -0.987       0.577\n",
      "BathroomQuality         -0.0772      0.363     -0.213      0.832      -0.794       0.640\n",
      "DiningRoomQuality        0.3449      0.297      1.160      0.248      -0.242       0.932\n",
      "CommonAreasQuality       0.2200      0.290      0.759      0.449      -0.352       0.792\n",
      "FitnessCenterQuality     0.1611      0.203      0.794      0.428      -0.240       0.562\n",
      "LaundryRoomQuality      -0.4289      0.217     -1.975      0.050      -0.858   -4.24e-05\n",
      "LivingRoomQuality       -0.2711      0.315     -0.860      0.391      -0.894       0.351\n",
      "MainEntranceQuality     -0.5086      0.402     -1.265      0.208      -1.302       0.285\n",
      "income                2.207e-06   1.89e-06      1.167      0.245   -1.53e-06    5.94e-06\n",
      "age                     -0.0015      0.008     -0.195      0.846      -0.016       0.013\n",
      "total_rent              -0.0001   7.16e-05     -2.030      0.044      -0.000   -3.97e-06\n",
      "==============================================================================\n",
      "Omnibus:                        6.262   Durbin-Watson:                   2.129\n",
      "Prob(Omnibus):                  0.044   Jarque-Bera (JB):                5.619\n",
      "Skew:                           0.362   Prob(JB):                       0.0602\n",
      "Kurtosis:                       2.523   Cond. No.                     9.39e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 9.39e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "x = final_metrics.drop(columns=['market', 'manager', 'recognition'])\n",
    "y = final_metrics['recognition']\n",
    "\n",
    "model = sm.OLS(y, x)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = final_metrics.drop(columns=['market', 'manager', 'recognition'])\n",
    "y = final_metrics['recognition']\n",
    "\n",
    "# Standardize predictors\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ElasticNetCV for feature selection\n",
    "enet = ElasticNetCV(cv=5, l1_ratio=0.5, random_state=42)\n",
    "enet.fit(X_scaled, y)\n",
    "\n",
    "# Get selected features (non-zero coefficients)\n",
    "selected_features = X.columns[enet.coef_ != 0]\n",
    "\n",
    "# Refit OLS on selected features\n",
    "X_selected = sm.add_constant(X[selected_features])  # add intercept\n",
    "ols_model = sm.OLS(y, X_selected)\n",
    "ols_results = ols_model.fit()\n",
    "\n",
    "# Print results\n",
    "print(ols_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c53b0",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b63a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fitted values and residuals\n",
    "fitted_vals = results.fittedvalues\n",
    "residuals = results.resid\n",
    "standardized_residuals = results.get_influence().resid_studentized_internal\n",
    "leverage = results.get_influence().hat_matrix_diag\n",
    "\n",
    "# 1. Residuals vs Fitted\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.residplot(x=fitted_vals, y=y, lowess=True, line_kws={'color': 'red'})\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Fitted')\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Normal Q-Q\n",
    "sm.qqplot(standardized_residuals, line='45', fit=True)\n",
    "plt.title('Normal Q-Q')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Scale-Location (Spread vs Fitted)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(fitted_vals, abs(standardized_residuals) ** 0.5)\n",
    "sns.regplot(x=fitted_vals, y=abs(standardized_residuals) ** 0.5,\n",
    "            scatter=False, lowess=True, line_kws={'color': 'red'})\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('√|Standardized Residuals|')\n",
    "plt.title('Scale-Location')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Leverage vs. Standardized Residuals\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(leverage, standardized_residuals)\n",
    "sns.regplot(x=leverage, y=standardized_residuals, scatter=False,\n",
    "            lowess=True, line_kws={'color': 'red'})\n",
    "plt.xlabel('Leverage')\n",
    "plt.ylabel('Standardized Residuals')\n",
    "plt.title('Residuals vs Leverage')\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brand_tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
